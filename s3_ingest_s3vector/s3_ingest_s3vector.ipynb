{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1249d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_ingest.py  (S3 Vectors version)\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "from llama_index.core import (\n",
    "    Document,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Config from environment ----------\n",
    "AWS_REGION = os.environ.get(\"AWS_REGION\", \"us-east-2\")\n",
    "AWS_PROFILE = os.environ.get(\"AWS_PROFILE\", \"022978668221_AdministratorAccess\")\n",
    "\n",
    "# S3 where raw docs live\n",
    "S3_BUCKET_ENV = os.environ.get(\"S3_BUCKET\", \"skiing-coach\")\n",
    "S3_OBJECT_KEY_ENV = os.environ.get(\"S3_OBJECT_KEY\", \"RagDoc/myFile.txt\")\n",
    "\n",
    "# S3 Vectors config\n",
    "# You must create this vector bucket + index ahead of time\n",
    "VECTOR_BUCKET_NAME = os.environ.get(\"VECTOR_BUCKET_NAME\", \"skiing-rag-vectors\")      # e.g. \"skiing-rag-vectors\"\n",
    "VECTOR_INDEX_NAME = os.environ.get(\"VECTOR_INDEX_NAME\", \"skiing-rag-index\")\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "LLM_MODEL = os.environ.get(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "EMBEDDING_DIM = int(os.environ.get(\"EMBEDDING_DIM\", \"1024\"))\n",
    "\n",
    "\n",
    "# ---------- AWS session & clients ----------\n",
    "\n",
    "if AWS_PROFILE:\n",
    "    session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION)\n",
    "else:\n",
    "    session = boto3.Session(region_name=AWS_REGION)\n",
    "\n",
    "s3_client = session.client(\"s3\")\n",
    "s3vectors_client = session.client(\"s3vectors\")\n",
    "\n",
    "\n",
    "# ---------- LLM & embedding config (must match your agent) ----------\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=0,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    dimensions=EMBEDDING_DIM,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78acac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Helpers ----------\n",
    "\n",
    "def fetch_s3_text(bucket: str, key: str) -> str:\n",
    "    \"\"\"Download one S3 object and decode as UTF-8 text.\"\"\"\n",
    "    print(f\"[INFO] Downloading s3://{bucket}/{key}\")\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    body = obj[\"Body\"].read()\n",
    "    try:\n",
    "        return body.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return body.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "\n",
    "def build_document(bucket: str, key: str) -> Document | None:\n",
    "    \"\"\"Build a LlamaIndex Document from one S3 object.\"\"\"\n",
    "    text = fetch_s3_text(bucket, key)\n",
    "    if not text.strip():\n",
    "        print(\"[WARN] S3 object is empty; skipping\")\n",
    "        return None\n",
    "\n",
    "    metadata = {\n",
    "        \"source_bucket\": bucket,\n",
    "        \"source_key\": key,\n",
    "        \"source_url\": f\"s3://{bucket}/{key}\",\n",
    "        \"title\": os.path.basename(key),\n",
    "    }\n",
    "\n",
    "    # doc_id makes re-ingest idempotent per file\n",
    "    doc_id = f\"s3://{bucket}/{key}\"\n",
    "\n",
    "    return Document(\n",
    "        text=text,\n",
    "        metadata=metadata,\n",
    "        doc_id=doc_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def _nodes_to_s3_vectors(doc: Document, nodes: list) -> None:\n",
    "    \"\"\"\n",
    "    Convert nodes to embeddings and write them into an S3 Vectors index.\n",
    "    We batch in chunks (<= 500 per call) to follow S3 Vectors guidance.\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "\n",
    "    for idx, node in enumerate(nodes):\n",
    "        content = node.get_content()\n",
    "        if not content.strip():\n",
    "            continue\n",
    "\n",
    "        # Get embedding for this chunk\n",
    "        embedding = embed_model.get_text_embedding(content)\n",
    "\n",
    "        key = f\"{doc.doc_id}#chunk-{idx}\"\n",
    "\n",
    "        # Metadata must be JSON-serializable and <= limits\n",
    "\n",
    "        preview = content[:400]  # adjust length if you like\n",
    "\n",
    "        metadata = {\n",
    "            \"doc_id\": doc.doc_id,\n",
    "            \"chunk_index\": idx,\n",
    "            \"title\": doc.metadata.get(\"title\"),\n",
    "            \"source_bucket\": doc.metadata.get(\"source_bucket\"),\n",
    "            \"source_key\": doc.metadata.get(\"source_key\"),\n",
    "            \"text_preview\": preview,\n",
    "        }\n",
    "\n",
    "        vectors.append(\n",
    "            {\n",
    "                \"key\": key,\n",
    "                \"data\": {\"float32\": embedding},\n",
    "                \"metadata\": metadata,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not vectors:\n",
    "        print(\"[INFO] No non-empty chunks to index.\")\n",
    "        return\n",
    "\n",
    "    # S3 Vectors recommends batching writes (up to 500 per request) :contentReference[oaicite:1]{index=1}\n",
    "    BATCH_SIZE = 500\n",
    "    for start in range(0, len(vectors), BATCH_SIZE):\n",
    "        batch = vectors[start : start + BATCH_SIZE]\n",
    "        print(f\"[INFO] Writing {len(batch)} vectors to S3 Vectors \"\n",
    "              f\"(bucket={VECTOR_BUCKET_NAME}, index={VECTOR_INDEX_NAME})\")\n",
    "        s3vectors_client.put_vectors(\n",
    "            vectorBucketName=VECTOR_BUCKET_NAME,\n",
    "            indexName=VECTOR_INDEX_NAME,\n",
    "            vectors=batch,\n",
    "        )\n",
    "\n",
    "\n",
    "def ingest_single_object(bucket: str, key: str) -> None:\n",
    "    \"\"\"Ingest one S3 object into the S3 Vectors index.\"\"\"\n",
    "    print(f\"[INFO] Ingesting s3://{bucket}/{key}\")\n",
    "\n",
    "    doc = build_document(bucket, key)\n",
    "    if doc is None:\n",
    "        print(\"[INFO] Nothing to ingest.\")\n",
    "        return\n",
    "\n",
    "    splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "    nodes = splitter.get_nodes_from_documents([doc])\n",
    "\n",
    "    _nodes_to_s3_vectors(doc, nodes)\n",
    "    print(\"[INFO] Ingest finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a3dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ingesting s3://skiing-coach/RagDoc/myFile.txt\n",
      "[INFO] Downloading s3://skiing-coach/RagDoc/myFile.txt\n",
      "[INFO] Writing 22 vectors to S3 Vectors (bucket=skiing-rag-vectors, index=skiing-rag-index)\n",
      "[INFO] Ingest finished.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Entry point ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not S3_BUCKET_ENV or not S3_OBJECT_KEY_ENV:\n",
    "        raise SystemExit(\"S3_BUCKET and S3_OBJECT_KEY must be set in the environment.\")\n",
    "\n",
    "    ingest_single_object(S3_BUCKET_ENV, S3_OBJECT_KEY_ENV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
